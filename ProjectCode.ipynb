{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data\n",
    "\n",
    "\n",
    "## Map Area\n",
    "\n",
    "Boston, MA, USA\n",
    "\n",
    "* https://www.openstreetmap.org/relation/2315704\n",
    "* https://mapzen.com/data/metro-extracts/metro/boston_massachusetts/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Dataset\n",
    "\n",
    "The goal of this process is to identify instances in the data set, where certain entries lack an expected level of consistency as well as propose appropriate edits.\n",
    "\n",
    "* abbreviated street designators, e.g. 'St' in 'Main St'\n",
    "* inconsistent postal codes, e.g. change 'Ma 02135' to '02135'\n",
    "* incorrect postal codes, e.g. postal codes in Boston, MA start with '01xxx' or '02xxx', therefore '03079' from New Hampshire is an example of an incorrect postal code.\n",
    "* non-uniform U.S. state abbreviation, e.g. 'Mass.', or incorrect state entry, e.g. 'NH'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the cell below to create a new sample file out of \"boston_massachusetts.osm\" once downloaded and unzipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating sample file as original OSM is 424 MB unzipped.\n",
    "# Parameter: take every k-th top level element\n",
    "# I used k = 8 for my sample file to reach the required minimum size of 50 MB (~53 MB) as\n",
    "# indicated in Project Specification\n",
    "# https://review.udacity.com/#!/rubrics/25/view\n",
    "\n",
    "OSM_FILE = \"boston_massachusetts.osm\"\n",
    "SAMPLE_FILE = \"boston_massachusetts_sample.osm\"\n",
    "\n",
    "k = 8\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    '''Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    '''\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Load dataset and search for incorrect street abbreviations.\n",
    "\n",
    "As a first step, the dataset is searched for incorrect abbreviations of street suffix. \n",
    "\n",
    "ex: 'St' in 'Main St'.\n",
    "\n",
    "_Reference:_ USPS Street Suffix Abbreviations\n",
    "http://pe.usps.gov/text/pub28/28apc_002.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the sample OSM file as provided in GitHub repository\n",
    "OSMFILE = \"boston_massachusetts_sample.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Way\", \"Circle\", \"Terrace\", \"Bend\", \"Manor\", \"Run\", \"Highway\",\n",
    "            \"Isle\", \"Hollow\", \"Cove\", \"Lake\", \"Trace\", \"Crescent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a group of auditing functions for street suffix\n",
    "def audit_street_type(street_types, street_name):\n",
    "    \"\"\" Checks if street name contains incorrect abbreviations, if so, adds it to the dictionary. \"\"\"\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    \"\"\" Returns a Boolean value \"\"\"\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    \"\"\" Iterates through document tags, and returns dictionary\n",
    "        of incorrect abbreviations (keys) and street names (value) that contain these abbreviations.\n",
    "    \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run audit and print results\n",
    "st_types = audit(OSMFILE)\n",
    "pprint.pprint(dict(st_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to correct street names using wrong suffix\n",
    "def update_name(name, mapping):\n",
    "    \"\"\" Substitutes incorrect abbreviation with correct one. \"\"\"\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        \n",
    "        temp= 0\n",
    "        try:\n",
    "            temp = int(street_type)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if street_type not in expected and temp == 0:\n",
    "            try:\n",
    "                name = re.sub(street_type_re, mapping[street_type], name)\n",
    "            except:\n",
    "                pass\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary mapping incorrect abbreviations to correct one.\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"ST\": \"Street\",\n",
    "            \"st\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"RD\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Trl\": \"Trail\",\n",
    "            \"Ter\": \"Terrace\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Pkwy\": \"Parkway\",\n",
    "            \"Bnd\": \"Bend\",\n",
    "            \"Mnr\": \"Manor\",\n",
    "            \"Ln\": \"Lane\",\n",
    "            \"street\": \"Street\",\n",
    "            \"AVE\": \"Avenue\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Cirlce\": \"Circle\",\n",
    "            \"DRIVE\": \"Drive\",\n",
    "            \"Cv\": \"Cove\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Druve\": \"Drive\",\n",
    "            \"Holw\": \"Hollow\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"HWY\": \"Highway\",\n",
    "            \"Pt\": \"Point\",\n",
    "            \"Trce\": \"Trace\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"Cres\": \"Crescent\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply corrections where incorrect detected v. mapping.\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Checking format and compatibility of postal codes with the area.\n",
    "\n",
    "US postal codes follow the 5-digit format. Some codes may differ due to additional signs such as 'MA 02118' or '02136-2460'.\n",
    "\n",
    "Also some postal codes may not be compatible with the Boston, MA area codes who start with \"01xxx\" or \"02xxx\". Such as '03079' (Salem in New Hampshire). Or they represent some other entry, such as '(617) 495-1000' is a phone number (Harvard U.).\n",
    "\n",
    "Note: some of these discrepancies may not appear in the 53 MB sample file but are present in the original 424 MB OSM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create a group of auditing functions for postal codes\n",
    "def audit_postcode(post_code, digits):\n",
    "    \"\"\" Checks if postal code is incompatible and adds it to the list if so. \"\"\"\n",
    "    if len(digits) != 5 or (digits[0:2] != '01' and digits[0:2] != '02'):\n",
    "        post_code.append(digits)\n",
    "\n",
    "\n",
    "def is_postalcode(elem):\n",
    "    \"\"\" Returns a Boolean value.\"\"\"\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    \"\"\" Iterates and returns list of inconsistent postal codes found in the document. \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    post_code = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postalcode(tag):\n",
    "                    audit_postcode(post_code, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return post_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run audit and print results\n",
    "postal_codes = audit(OSMFILE)\n",
    "print postal_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to correct format of postal codes\n",
    "def update_zip(post_code):\n",
    "    \"\"\" Extracts 5-digit postal codes from postal codes in different formats\n",
    "        and deletes postal codes that do not correspond to Massachussets area.\n",
    "    \"\"\"\n",
    "    \n",
    "    if post_code[0:2] == 'Ma' or post_code[0:2] == 'MA':\n",
    "        post_code = post_code[3:].strip()\n",
    "    \n",
    "    if len(post_code) >5 and len(post_code) == 10 and (post_code[0:2] == '01' or post_code[0:2] == '02'):\n",
    "        post_code = post_code[0:5]\n",
    "    elif len(post_code) < 5 or (post_code[0:2] != '01' and post_code[0:2] != '02') :\n",
    "        post_code = ''\n",
    "    elif len(post_code) > 5 and post_code[5]==' ':\n",
    "        post_code = post_code[0:5]\n",
    "    elif len(post_code)>5:\n",
    "        post_code = ''\n",
    "\n",
    "    return post_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply corrections where incorrect detected\n",
    "for code in postal_codes:\n",
    "    better_code = update_zip(code)\n",
    "    print code, \"=>\", better_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Analyzing U.S. state entry\n",
    "\n",
    "All state entries should either contain the official abbreviation for Massachusetts, 'MA', \n",
    "as opposed to 'Mass', 'mass', 'ma', and 'Ma' to 'MA';\n",
    "\n",
    "or an empty string, if the state entry is not related to 'MA',\n",
    "such as 'New York', 'NH', ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create a group of auditing functions for state entry\n",
    "def audit_state(states, state):\n",
    "    \"\"\" Checks if state entry is inconsistent and, if so, adds it to the list.\"\"\"\n",
    "    if state != 'MA':\n",
    "        states.append(state)\n",
    "\n",
    "\n",
    "def is_state(elem):\n",
    "    \"\"\" Returns a Boolean value.\"\"\"\n",
    "    return (elem.attrib['k'] == \"addr:state\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    \"\"\" Iterates and returns list of inconsistent state entris found in the document.\"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    states = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_state(tag):\n",
    "                    audit_state(states, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run audit and print results\n",
    "states = audit(OSMFILE)\n",
    "print states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to correct state entries\n",
    "def update_state(state):\n",
    "    \"\"\" Deletes U.S. state entries not related to Massachussets and formats all remaining to 'MA'.\"\"\"\n",
    "    \n",
    "    if state.startswith('ma') or state.startswith('Ma') or state.startswith('MA') or state == 'M':\n",
    "        state = 'MA'\n",
    "    else:\n",
    "        state = ''\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply corrections where incorrect detected\n",
    "for state in states:\n",
    "    better_state = update_state(state)\n",
    "    print state, \"=>\", better_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Convert XML to CSV format\n",
    "\n",
    "Using some code from the \"Case Study: OpenStreetMap Data[SQL]\".\n",
    "\n",
    "Follows the schema provided in Project Details instructions.\n",
    "https://gist.github.com/swwelch/f1144229848b407e0a5d13fcb7fbbd6f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regular expression compiler patterns.\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input element is a \"node\" or a \"way\" then clean, shape and parse to corresponding dictionary.\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for field in node_attr_fields:\n",
    "            node_attribs[field] = element.attrib[field]\n",
    "    \n",
    "    if element.tag == 'way':\n",
    "        for field in way_attr_fields:\n",
    "            way_attribs[field] = element.attrib[field]\n",
    "        \n",
    "        position = 0\n",
    "        temp = {}\n",
    "        for tag in element.iter(\"nd\"):\n",
    "            temp['id'] = element.attrib[\"id\"]\n",
    "            temp['node_id'] = tag.attrib[\"ref\"]\n",
    "            temp['position'] = position\n",
    "            position += 1\n",
    "            way_nodes.append(temp.copy())\n",
    "\n",
    "    temp = {}\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        temp['id'] = element.attrib[\"id\"]\n",
    "        if \":\" in tag.attrib[\"k\"]:\n",
    "            newKey = re.split(\":\",tag.attrib[\"k\"],1)\n",
    "            temp['key'] = newKey[1]\n",
    "            if temp['key'] == 'postcode':\n",
    "                temp['value'] = update_zip(tag.attrib[\"v\"])\n",
    "            elif temp['key'] == 'state':\n",
    "                temp['value'] = update_state(tag.attrib[\"v\"])\n",
    "            elif temp['key'] == 'street':\n",
    "                temp['value'] = update_name(tag.attrib[\"v\"],mapping)\n",
    "            else:\n",
    "                temp['value'] = tag.attrib[\"v\"]\n",
    "            temp[\"type\"] = newKey[0]\n",
    "        else:\n",
    "            temp['key'] = tag.attrib[\"k\"]\n",
    "            if temp['key'] == 'postcode':\n",
    "                temp['value'] = update_zip(tag.attrib[\"v\"])\n",
    "            elif temp['key'] == 'state':\n",
    "                temp['value'] = update_state(tag.attrib[\"v\"])\n",
    "            elif temp['key'] == 'street':\n",
    "                temp['value'] = update_name(tag.attrib[\"v\"],mapping)\n",
    "            else:\n",
    "                temp['value'] = tag.attrib[\"v\"]\n",
    "            temp[\"type\"] = default_tag_type\n",
    "        tags.append(temp.copy())  \n",
    "        \n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_map(OSMFILE, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5 - Import CSV files into SQL tables\n",
    "\n",
    "Using the code provided by Project Details instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect(\"BostonMA.db\")\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the csv file as a dictionary, format the data as a list of tuples:\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'].decode(\"utf-8\"), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'].decode(\"utf-8\"), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO ways_tags(id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Overview of the Data\n",
    "\n",
    "The following SQL queries give a general summary of the data as well as some other interesting facts.\n",
    "\n",
    "### File sizes\n",
    "\n",
    "boston_massachusetts.osm .............. 424 MB  \n",
    "boston_massachusetts_sample.osm .. 53 MB  \n",
    "BostonMA.db ................................... 31 MB   \n",
    "nodes.csv ............................... 19 MB   \n",
    "nodes_tags.csv .......................... 7 MB   \n",
    "ways.csv ................................. 3 MB   \n",
    "ways_nodes.csv ......................... 7 MB   \n",
    "ways_tags.csv .......................... 3 MB   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"BostonMA.db\")\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) FROM nodes;\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) FROM ways;\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(DISTINCT(temp.uid)) FROM (SELECT user, uid FROM ways UNION ALL SELECT user, uid FROM nodes) as temp;\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT temp.user, count(*) as posts FROM (SELECT user, uid FROM ways UNION ALL SELECT user, uid FROM nodes) as temp \\\n",
    "GROUP BY temp.user ORDER BY posts DESC LIMIT 10;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 common Way tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT key, count(*) FROM ways_tags GROUP BY 1 ORDER BY count(*) DESC LIMIT 5;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 common Node tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT key,count(*) FROM nodes_tags GROUP BY 1 ORDER BY count(*) DESC LIMIT 5;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of wheelchair access information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) FROM (SELECT key,value FROM ways_tags UNION ALL SELECT key,value FROM nodes_tags) \\\n",
    "WHERE key='wheelchair';\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) FROM (SELECT key,value FROM ways_tags UNION ALL SELECT key,value FROM nodes_tags) \\\n",
    "WHERE key='amenity';\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT temp.value, count(*) as num \\\n",
    "FROM (SELECT key,value FROM ways_tags UNION ALL SELECT key,value FROM nodes_tags) as temp \\\n",
    "WHERE temp.key='amenity' GROUP BY temp.value ORDER BY num DESC LIMIT 20;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 postal codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT temp.value, count(*) as num \\\n",
    "FROM (SELECT key,value FROM ways_tags UNION ALL SELECT key,value FROM nodes_tags) as temp \\\n",
    "WHERE temp.key = 'postcode' GROUP BY temp.value ORDER BY num DESC LIMIT 10;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Cities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT temp.value, count(*) as num \\\n",
    "FROM (SELECT key,value FROM ways_tags UNION ALL SELECT key,value FROM nodes_tags) as temp \\\n",
    "WHERE temp.key = 'city' GROUP BY temp.value ORDER BY num DESC LIMIT 10;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
